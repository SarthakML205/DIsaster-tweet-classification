{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5608f8e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-20T09:29:29.865811Z",
     "iopub.status.busy": "2023-06-20T09:29:29.865409Z",
     "iopub.status.idle": "2023-06-20T09:29:29.880536Z",
     "shell.execute_reply": "2023-06-20T09:29:29.879557Z"
    },
    "papermill": {
     "duration": 0.027132,
     "end_time": "2023-06-20T09:29:29.883753",
     "exception": false,
     "start_time": "2023-06-20T09:29:29.856621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/nlp-getting-started/sample_submission.csv\n",
      "/kaggle/input/nlp-getting-started/train.csv\n",
      "/kaggle/input/nlp-getting-started/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29f882cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T09:29:29.899090Z",
     "iopub.status.busy": "2023-06-20T09:29:29.898710Z",
     "iopub.status.idle": "2023-06-20T09:29:34.303842Z",
     "shell.execute_reply": "2023-06-20T09:29:34.302638Z"
    },
    "papermill": {
     "duration": 4.415952,
     "end_time": "2023-06-20T09:29:34.306522",
     "exception": false,
     "start_time": "2023-06-20T09:29:29.890570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Archive:  /usr/share/nltk_data/corpora/wordnet.zip\r\n",
      "   creating: /usr/share/nltk_data/corpora/wordnet/\r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/README  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \r\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re, string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edf65389",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T09:29:34.323926Z",
     "iopub.status.busy": "2023-06-20T09:29:34.323165Z",
     "iopub.status.idle": "2023-06-20T09:29:34.423498Z",
     "shell.execute_reply": "2023-06-20T09:29:34.422396Z"
    },
    "papermill": {
     "duration": 0.112149,
     "end_time": "2023-06-20T09:29:34.426131",
     "exception": false,
     "start_time": "2023-06-20T09:29:34.313982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 5)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\n",
    "df_test = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53b3d66f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T09:29:34.443890Z",
     "iopub.status.busy": "2023-06-20T09:29:34.442523Z",
     "iopub.status.idle": "2023-06-20T09:29:34.476895Z",
     "shell.execute_reply": "2023-06-20T09:29:34.475442Z"
    },
    "papermill": {
     "duration": 0.045933,
     "end_time": "2023-06-20T09:29:34.479716",
     "exception": false,
     "start_time": "2023-06-20T09:29:34.433783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea823ccd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T09:29:34.496430Z",
     "iopub.status.busy": "2023-06-20T09:29:34.496011Z",
     "iopub.status.idle": "2023-06-20T09:29:34.523551Z",
     "shell.execute_reply": "2023-06-20T09:29:34.522314Z"
    },
    "papermill": {
     "duration": 0.03873,
     "end_time": "2023-06-20T09:29:34.525975",
     "exception": false,
     "start_time": "2023-06-20T09:29:34.487245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4342\n",
      "1    3271\n",
      "Name: target, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_train['target'].value_counts()\n",
    "print(x)\n",
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "841e7c1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T09:29:34.546353Z",
     "iopub.status.busy": "2023-06-20T09:29:34.545862Z",
     "iopub.status.idle": "2023-06-20T09:29:34.557393Z",
     "shell.execute_reply": "2023-06-20T09:29:34.556068Z"
    },
    "papermill": {
     "duration": 0.023602,
     "end_time": "2023-06-20T09:29:34.559758",
     "exception": false,
     "start_time": "2023-06-20T09:29:34.536156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " people receive wildfires evacuation orders in california\n"
     ]
    }
   ],
   "source": [
    "text = df_train['text'][3]\n",
    "# removing punctutations, extraspaces, digits, html_tags, and lower_casing the text\n",
    "def preprocess(text):\n",
    "    text = text.lower() #lowercase text\n",
    "    text = text.strip() #removin the whitespaces\n",
    "    text = re.compile('<.*?>').sub('',text) #removing html tags\n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub('', text) #remove punctuations with spaces.\n",
    "    text = re.sub('\\s+', ' ', text) #remove extra spaces\n",
    "    text = re.sub(r'\\[[0-9]*\\]', ' ', text )\n",
    "    text = re.sub(r'[^\\w\\s]',\" \", str(text).lower().strip()) \n",
    "    text = re.sub(r'\\d', ' ', text)\n",
    "    text = re.sub(r'\\d', ' ', text)\n",
    "    text = re.sub(r'\\s+',' ', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "text = preprocess(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7bd84ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T09:29:34.578382Z",
     "iopub.status.busy": "2023-06-20T09:29:34.577880Z",
     "iopub.status.idle": "2023-06-20T09:29:34.604462Z",
     "shell.execute_reply": "2023-06-20T09:29:34.602993Z"
    },
    "papermill": {
     "duration": 0.039418,
     "end_time": "2023-06-20T09:29:34.607420",
     "exception": false,
     "start_time": "2023-06-20T09:29:34.568002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#removing stopwords from the text. \n",
    "\n",
    "def stopword(string):\n",
    "    a = [i for i in string.split() if i not in stopwords.words('english')]\n",
    "    return \" \".join(a)\n",
    "\n",
    "text = stopword(text)\n",
    "snow = SnowballStemmer('english')\n",
    "\n",
    "def stemming(string):\n",
    "    a = [snow.stem(i) for i in word_tokenize(string)]\n",
    "    return \" \".join(a)\n",
    "\n",
    "text = stemming(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98246d50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T09:29:34.625613Z",
     "iopub.status.busy": "2023-06-20T09:29:34.624935Z",
     "iopub.status.idle": "2023-06-20T09:29:34.631860Z",
     "shell.execute_reply": "2023-06-20T09:29:34.630662Z"
    },
    "papermill": {
     "duration": 0.018797,
     "end_time": "2023-06-20T09:29:34.634106",
     "exception": false,
     "start_time": "2023-06-20T09:29:34.615309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "wl = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ \n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV \n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d290f59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T09:29:34.651771Z",
     "iopub.status.busy": "2023-06-20T09:29:34.651388Z",
     "iopub.status.idle": "2023-06-20T09:29:37.379502Z",
     "shell.execute_reply": "2023-06-20T09:29:37.378229Z"
    },
    "papermill": {
     "duration": 2.740235,
     "end_time": "2023-06-20T09:29:37.382273",
     "exception": false,
     "start_time": "2023-06-20T09:29:34.642038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peopl receiv wildfir evacu order california\n"
     ]
    }
   ],
   "source": [
    "def lemmatizer(string):\n",
    "    word_pos_tags = nltk.pos_tag(word_tokenize(string))\n",
    "    a = [wl.lemmatize(tag[0], get_wordnet_pos(tag[1])) for idx, tag in enumerate(word_pos_tags)]\n",
    "    return \" \".join(a) \n",
    "\n",
    "text = lemmatizer(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4345d0ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T09:29:37.399946Z",
     "iopub.status.busy": "2023-06-20T09:29:37.399573Z",
     "iopub.status.idle": "2023-06-20T09:30:06.676353Z",
     "shell.execute_reply": "2023-06-20T09:30:06.675346Z"
    },
    "papermill": {
     "duration": 29.288966,
     "end_time": "2023-06-20T09:30:06.679178",
     "exception": false,
     "start_time": "2023-06-20T09:29:37.390212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# final precessing of the training data.\n",
    "\n",
    "def finalpreprocess(string):\n",
    "    return lemmatizer(stopword(preprocess(string)))\n",
    "\n",
    "df_train[\"clean_text\"] = df_train['text'].apply(lambda x : finalpreprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74a201b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T09:30:06.697213Z",
     "iopub.status.busy": "2023-06-20T09:30:06.696807Z",
     "iopub.status.idle": "2023-06-20T09:30:06.710189Z",
     "shell.execute_reply": "2023-06-20T09:30:06.709064Z"
    },
    "papermill": {
     "duration": 0.025622,
     "end_time": "2023-06-20T09:30:06.712871",
     "exception": false,
     "start_time": "2023-06-20T09:30:06.687249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deed reason earthquake may allah forgive u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>resident ask shelter place notify officer evac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfire evacuation order calif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>get sent photo ruby alaska smoke wildfires pou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                         clean_text  \n",
       "0       1         deed reason earthquake may allah forgive u  \n",
       "1       1              forest fire near la ronge sask canada  \n",
       "2       1  resident ask shelter place notify officer evac...  \n",
       "3       1  people receive wildfire evacuation order calif...  \n",
       "4       1  get sent photo ruby alaska smoke wildfires pou...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36893193",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T09:30:06.731722Z",
     "iopub.status.busy": "2023-06-20T09:30:06.731333Z",
     "iopub.status.idle": "2023-06-20T09:30:06.952871Z",
     "shell.execute_reply": "2023-06-20T09:30:06.951500Z"
    },
    "papermill": {
     "duration": 0.234036,
     "end_time": "2023-06-20T09:30:06.955733",
     "exception": false,
     "start_time": "2023-06-20T09:30:06.721697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val , y_train, y_val = train_test_split(df_train['clean_text'], df_train['target'], test_size = 0.2, shuffle = True)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf = True)\n",
    "\n",
    "X_train_vectors_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "#only transform x_text( not fit and transform)\n",
    "X_val_vectors_tfidf = tfidf_vectorizer.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c186db8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T09:30:06.974211Z",
     "iopub.status.busy": "2023-06-20T09:30:06.973734Z",
     "iopub.status.idle": "2023-06-20T09:30:07.074956Z",
     "shell.execute_reply": "2023-06-20T09:30:07.073385Z"
    },
    "papermill": {
     "duration": 0.115775,
     "end_time": "2023-06-20T09:30:07.079700",
     "exception": false,
     "start_time": "2023-06-20T09:30:06.963925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       883\n",
      "           1       0.77      0.72      0.75       640\n",
      "\n",
      "    accuracy                           0.80      1523\n",
      "   macro avg       0.79      0.79      0.79      1523\n",
      "weighted avg       0.79      0.80      0.79      1523\n",
      "\n",
      "Confusion matrix: \n",
      " [[748 135]\n",
      " [176 464]]\n",
      "\n",
      "AUC:  0.8530674900906001\n"
     ]
    }
   ],
   "source": [
    "# using Logistic Regressor as linear model.\n",
    "lr = LogisticRegression( solver = 'liblinear', C=10, penalty = \"l2\")\n",
    "lr.fit(X_train_vectors_tfidf, y_train)\n",
    "\n",
    "# predicting y value for the test data set.\n",
    "y_pred = lr.predict(X_val_vectors_tfidf)\n",
    "y_prob = lr.predict_proba(X_val_vectors_tfidf)[ : ,1]\n",
    "\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_val, y_pred))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve( y_val, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"\\nAUC: \", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8106dd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T09:30:07.116775Z",
     "iopub.status.busy": "2023-06-20T09:30:07.115918Z",
     "iopub.status.idle": "2023-06-20T09:30:07.161302Z",
     "shell.execute_reply": "2023-06-20T09:30:07.160368Z"
    },
    "papermill": {
     "duration": 0.066682,
     "end_time": "2023-06-20T09:30:07.163693",
     "exception": false,
     "start_time": "2023-06-20T09:30:07.097011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.85       883\n",
      "           1       0.84      0.67      0.75       640\n",
      "\n",
      "    accuracy                           0.81      1523\n",
      "   macro avg       0.82      0.79      0.80      1523\n",
      "weighted avg       0.81      0.81      0.80      1523\n",
      "\n",
      "Confusion matrix: \n",
      " [[803  80]\n",
      " [211 429]]\n",
      "\n",
      "AUC:  0.8513421928086069\n"
     ]
    }
   ],
   "source": [
    "# using MultinomialNB \n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_vectors_tfidf, y_train)\n",
    "\n",
    "#predicting y value for text dataset \n",
    "y_pred = nb.predict(X_val_vectors_tfidf)\n",
    "y_prob = nb.predict_proba(X_val_vectors_tfidf)[ : ,1]\n",
    "\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_val, y_pred))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve( y_val, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"\\nAUC: \", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531b92f1",
   "metadata": {
    "papermill": {
     "duration": 0.00807,
     "end_time": "2023-06-20T09:30:07.180503",
     "exception": false,
     "start_time": "2023-06-20T09:30:07.172433",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "using logistic regresor as it has better auc score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f06f04c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T09:30:07.199253Z",
     "iopub.status.busy": "2023-06-20T09:30:07.198525Z",
     "iopub.status.idle": "2023-06-20T09:30:19.870171Z",
     "shell.execute_reply": "2023-06-20T09:30:19.868998Z"
    },
    "papermill": {
     "duration": 12.684295,
     "end_time": "2023-06-20T09:30:19.873002",
     "exception": false,
     "start_time": "2023-06-20T09:30:07.188707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id keyword location                                               text  \\\n",
      "0   0     NaN      NaN                 Just happened a terrible car crash   \n",
      "1   2     NaN      NaN  Heard about #earthquake is different cities, s...   \n",
      "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...   \n",
      "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires   \n",
      "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan   \n",
      "\n",
      "                                          clean_text  predict_prob  target  \n",
      "0                          happen terrible car crash      0.970597       1  \n",
      "1  heard earthquake different city stay safe ever...      0.750173       1  \n",
      "2  forest fire spot pond geese flee across street...      0.905409       1  \n",
      "3                  apocalypse light spokane wildfire      0.879474       1  \n",
      "4                 typhoon soudelor kill china taiwan      0.994711       1  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       1\n",
       "2         3       1\n",
       "3         9       1\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       1\n",
       "3259  10865       1\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       1\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['clean_text'] = df_test['text'].apply(lambda x : finalpreprocess(x))\n",
    "X_test = df_test['clean_text']\n",
    "# converting the X_text to vectors\n",
    "\n",
    "X_test_vectors_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "#using trained model on X_vector. \n",
    "\n",
    "y_pred = lr.predict(X_test_vectors_tfidf)\n",
    "y_prob = lr.predict_proba(X_test_vectors_tfidf)[ : , 1]\n",
    "df_test['predict_prob'] = y_prob\n",
    "df_test['target'] = y_pred\n",
    "\n",
    "print(df_test.head())\n",
    "\n",
    "final = df_test[['id', 'target']].reset_index(drop = True)\n",
    "final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a2f8937",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T09:30:19.892738Z",
     "iopub.status.busy": "2023-06-20T09:30:19.892338Z",
     "iopub.status.idle": "2023-06-20T09:30:19.911839Z",
     "shell.execute_reply": "2023-06-20T09:30:19.910525Z"
    },
    "papermill": {
     "duration": 0.032485,
     "end_time": "2023-06-20T09:30:19.914575",
     "exception": false,
     "start_time": "2023-06-20T09:30:19.882090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c485aa7e",
   "metadata": {
    "papermill": {
     "duration": 0.008441,
     "end_time": "2023-06-20T09:30:19.931937",
     "exception": false,
     "start_time": "2023-06-20T09:30:19.923496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 64.810539,
   "end_time": "2023-06-20T09:30:21.367234",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-20T09:29:16.556695",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
